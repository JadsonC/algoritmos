{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Expressões Regulares"
      ],
      "metadata": {
        "id": "xhaHB2T0k9EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "x3a_aef7k254"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrc85qXCdxOe",
        "outputId": "4a72f5ec-8014-4584-c6a0-fca3daf81c1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bibliotecário', 'biblioteca']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#encontrar palavras a partir de um stem\n",
        "texto = \"o bibliotecário abriu a biblioteca\"\n",
        "resultado = re.findall(r'bib\\w*', texto)\n",
        "resultado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encontrar a posição de uma palavra no texto\n",
        "texto = \"uma pessoa boa\"\n",
        "resultado = re.search(r'pessoa', texto)\n",
        "resultado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRUsHWiQfUOs",
        "outputId": "91f4b805-73d4-4a37-f376-68a887aae2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(4, 10), match='pessoa'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenização\n",
        "texto = \"Algum tempo hesitei se devia abrir estas memórias.\"\n",
        "resultado = re.findall(r\"\\w+(?:[-’]\\w+)*|’|[-.(]+|\\S\\w*\", texto)\n",
        "resultado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV5DfBKuhgp_",
        "outputId": "8498f66f-c282-4460-f85a-379a25c2adeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Algum', 'tempo', 'hesitei', 'se', 'devia', 'abrir', 'estas', 'memórias', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b5dag0OhkPsY",
        "outputId": "9341690d-2546-435a-905a-0753bf445e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Algum tempo hesitei se devia abrir estas memórias .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLTK"
      ],
      "metadata": {
        "id": "2K8spIaiwwBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import machado\n",
        "from nltk.text import Text\n",
        "from nltk import bigrams\n",
        "from nltk.corpus import mac_morpho\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "\n",
        "nltk.download('mac_morpho')\n",
        "nltk.download('machado')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')"
      ],
      "metadata": {
        "id": "rlrfk-x0xFU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fe44f1-de20-4d10-962f-60791fbe90d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data] Downloading package machado to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Usando um Corpus e a Classe Text"
      ],
      "metadata": {
        "id": "pqh9Cu14yD3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "machado.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l34GzyoyImA",
        "outputId": "0e002078-f144-4dbc-db5a-5a3d25703374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['contos/macn001.txt',\n",
              " 'contos/macn002.txt',\n",
              " 'contos/macn003.txt',\n",
              " 'contos/macn004.txt',\n",
              " 'contos/macn005.txt',\n",
              " 'contos/macn006.txt',\n",
              " 'contos/macn007.txt',\n",
              " 'contos/macn008.txt',\n",
              " 'contos/macn009.txt',\n",
              " 'contos/macn010.txt',\n",
              " 'contos/macn011.txt',\n",
              " 'contos/macn012.txt',\n",
              " 'contos/macn013.txt',\n",
              " 'contos/macn014.txt',\n",
              " 'contos/macn015.txt',\n",
              " 'contos/macn016.txt',\n",
              " 'contos/macn017.txt',\n",
              " 'contos/macn018.txt',\n",
              " 'contos/macn019.txt',\n",
              " 'contos/macn020.txt',\n",
              " 'contos/macn021.txt',\n",
              " 'contos/macn022.txt',\n",
              " 'contos/macn023.txt',\n",
              " 'contos/macn024.txt',\n",
              " 'contos/macn025.txt',\n",
              " 'contos/macn026.txt',\n",
              " 'contos/macn027.txt',\n",
              " 'contos/macn028.txt',\n",
              " 'contos/macn029.txt',\n",
              " 'contos/macn030.txt',\n",
              " 'contos/macn031.txt',\n",
              " 'contos/macn032.txt',\n",
              " 'contos/macn033.txt',\n",
              " 'contos/macn034.txt',\n",
              " 'contos/macn035.txt',\n",
              " 'contos/macn036.txt',\n",
              " 'contos/macn037.txt',\n",
              " 'contos/macn038.txt',\n",
              " 'contos/macn039.txt',\n",
              " 'contos/macn040.txt',\n",
              " 'contos/macn041.txt',\n",
              " 'contos/macn042.txt',\n",
              " 'contos/macn043.txt',\n",
              " 'contos/macn044.txt',\n",
              " 'contos/macn045.txt',\n",
              " 'contos/macn046.txt',\n",
              " 'contos/macn047.txt',\n",
              " 'contos/macn048.txt',\n",
              " 'contos/macn049.txt',\n",
              " 'contos/macn050.txt',\n",
              " 'contos/macn051.txt',\n",
              " 'contos/macn052.txt',\n",
              " 'contos/macn053.txt',\n",
              " 'contos/macn054.txt',\n",
              " 'contos/macn055.txt',\n",
              " 'contos/macn056.txt',\n",
              " 'contos/macn057.txt',\n",
              " 'contos/macn058.txt',\n",
              " 'contos/macn059.txt',\n",
              " 'contos/macn060.txt',\n",
              " 'contos/macn061.txt',\n",
              " 'contos/macn062.txt',\n",
              " 'contos/macn063.txt',\n",
              " 'contos/macn064.txt',\n",
              " 'contos/macn065.txt',\n",
              " 'contos/macn066.txt',\n",
              " 'contos/macn067.txt',\n",
              " 'contos/macn068.txt',\n",
              " 'contos/macn069.txt',\n",
              " 'contos/macn070.txt',\n",
              " 'contos/macn071.txt',\n",
              " 'contos/macn072.txt',\n",
              " 'contos/macn073.txt',\n",
              " 'contos/macn074.txt',\n",
              " 'contos/macn075.txt',\n",
              " 'contos/macn076.txt',\n",
              " 'contos/macn077.txt',\n",
              " 'contos/macn078.txt',\n",
              " 'contos/macn079.txt',\n",
              " 'contos/macn080.txt',\n",
              " 'contos/macn081.txt',\n",
              " 'contos/macn082.txt',\n",
              " 'contos/macn083.txt',\n",
              " 'contos/macn084.txt',\n",
              " 'contos/macn085.txt',\n",
              " 'contos/macn086.txt',\n",
              " 'contos/macn087.txt',\n",
              " 'contos/macn088.txt',\n",
              " 'contos/macn089.txt',\n",
              " 'contos/macn090.txt',\n",
              " 'contos/macn091.txt',\n",
              " 'contos/macn092.txt',\n",
              " 'contos/macn093.txt',\n",
              " 'contos/macn094.txt',\n",
              " 'contos/macn095.txt',\n",
              " 'contos/macn096.txt',\n",
              " 'contos/macn097.txt',\n",
              " 'contos/macn098.txt',\n",
              " 'contos/macn099.txt',\n",
              " 'contos/macn100.txt',\n",
              " 'contos/macn101.txt',\n",
              " 'contos/macn102.txt',\n",
              " 'contos/macn103.txt',\n",
              " 'contos/macn104.txt',\n",
              " 'contos/macn105.txt',\n",
              " 'contos/macn106.txt',\n",
              " 'contos/macn107.txt',\n",
              " 'contos/macn108.txt',\n",
              " 'contos/macn109.txt',\n",
              " 'contos/macn110.txt',\n",
              " 'contos/macn111.txt',\n",
              " 'contos/macn112.txt',\n",
              " 'contos/macn113.txt',\n",
              " 'contos/macn114.txt',\n",
              " 'contos/macn115.txt',\n",
              " 'contos/macn116.txt',\n",
              " 'contos/macn117.txt',\n",
              " 'contos/macn118.txt',\n",
              " 'contos/macn119.txt',\n",
              " 'contos/macn120.txt',\n",
              " 'contos/macn121.txt',\n",
              " 'contos/macn122.txt',\n",
              " 'contos/macn123.txt',\n",
              " 'contos/macn124.txt',\n",
              " 'contos/macn125.txt',\n",
              " 'contos/macn126.txt',\n",
              " 'contos/macn127.txt',\n",
              " 'contos/macn128.txt',\n",
              " 'contos/macn129.txt',\n",
              " 'contos/macn130.txt',\n",
              " 'contos/macn131.txt',\n",
              " 'contos/macn132.txt',\n",
              " 'contos/macn133.txt',\n",
              " 'contos/macn134.txt',\n",
              " 'contos/macn135.txt',\n",
              " 'contos/macn136.txt',\n",
              " 'contos/macn137.txt',\n",
              " 'critica/mact01.txt',\n",
              " 'critica/mact02.txt',\n",
              " 'critica/mact03.txt',\n",
              " 'critica/mact04.txt',\n",
              " 'critica/mact05.txt',\n",
              " 'critica/mact06.txt',\n",
              " 'critica/mact07.txt',\n",
              " 'critica/mact08.txt',\n",
              " 'critica/mact09.txt',\n",
              " 'critica/mact10.txt',\n",
              " 'critica/mact11.txt',\n",
              " 'critica/mact12.txt',\n",
              " 'critica/mact13.txt',\n",
              " 'critica/mact14.txt',\n",
              " 'critica/mact15.txt',\n",
              " 'critica/mact16.txt',\n",
              " 'critica/mact17.txt',\n",
              " 'critica/mact18.txt',\n",
              " 'critica/mact19.txt',\n",
              " 'critica/mact20.txt',\n",
              " 'critica/mact21.txt',\n",
              " 'critica/mact22.txt',\n",
              " 'critica/mact23.txt',\n",
              " 'critica/mact24.txt',\n",
              " 'critica/mact25.txt',\n",
              " 'critica/mact26.txt',\n",
              " 'critica/mact27.txt',\n",
              " 'critica/mact28.txt',\n",
              " 'critica/mact29.txt',\n",
              " 'critica/mact30.txt',\n",
              " 'critica/mact31.txt',\n",
              " 'critica/mact32.txt',\n",
              " 'critica/mact33.txt',\n",
              " 'critica/mact34.txt',\n",
              " 'critica/mact35.txt',\n",
              " 'critica/mact36.txt',\n",
              " 'critica/mact37.txt',\n",
              " 'critica/mact38.txt',\n",
              " 'critica/mact39.txt',\n",
              " 'critica/mact40.txt',\n",
              " 'critica/mact41.txt',\n",
              " 'critica/mact42.txt',\n",
              " 'critica/mact43.txt',\n",
              " 'critica/mact44.txt',\n",
              " 'critica/mact45.txt',\n",
              " 'cronica/macr01.txt',\n",
              " 'cronica/macr02.txt',\n",
              " 'cronica/macr03.txt',\n",
              " 'cronica/macr04.txt',\n",
              " 'cronica/macr05.txt',\n",
              " 'cronica/macr06.txt',\n",
              " 'cronica/macr07.txt',\n",
              " 'cronica/macr08.txt',\n",
              " 'cronica/macr09.txt',\n",
              " 'cronica/macr10.txt',\n",
              " 'cronica/macr11.txt',\n",
              " 'cronica/macr12.txt',\n",
              " 'cronica/macr13.txt',\n",
              " 'cronica/macr14.txt',\n",
              " 'cronica/macr15.txt',\n",
              " 'cronica/macr16.txt',\n",
              " 'cronica/macr17.txt',\n",
              " 'cronica/macr18.txt',\n",
              " 'cronica/macr19.txt',\n",
              " 'cronica/macr20.txt',\n",
              " 'cronica/macr21.txt',\n",
              " 'cronica/macr22.txt',\n",
              " 'cronica/macr23.txt',\n",
              " 'cronica/macr24.txt',\n",
              " 'miscelanea/mams01.txt',\n",
              " 'miscelanea/mams02.txt',\n",
              " 'miscelanea/mams03.txt',\n",
              " 'miscelanea/mams04.txt',\n",
              " 'miscelanea/mams05.txt',\n",
              " 'miscelanea/mams06.txt',\n",
              " 'miscelanea/mams07.txt',\n",
              " 'miscelanea/mams08.txt',\n",
              " 'miscelanea/mams09.txt',\n",
              " 'miscelanea/mams10.txt',\n",
              " 'poesia/maps01.txt',\n",
              " 'poesia/maps02.txt',\n",
              " 'poesia/maps03.txt',\n",
              " 'poesia/maps04.txt',\n",
              " 'poesia/maps05.txt',\n",
              " 'poesia/maps06.txt',\n",
              " 'poesia/maps07.txt',\n",
              " 'romance/marm01.txt',\n",
              " 'romance/marm02.txt',\n",
              " 'romance/marm03.txt',\n",
              " 'romance/marm04.txt',\n",
              " 'romance/marm05.txt',\n",
              " 'romance/marm06.txt',\n",
              " 'romance/marm07.txt',\n",
              " 'romance/marm08.txt',\n",
              " 'romance/marm09.txt',\n",
              " 'romance/marm10.txt',\n",
              " 'teatro/matt01.txt',\n",
              " 'teatro/matt02.txt',\n",
              " 'teatro/matt03.txt',\n",
              " 'teatro/matt04.txt',\n",
              " 'teatro/matt05.txt',\n",
              " 'teatro/matt06.txt',\n",
              " 'teatro/matt07.txt',\n",
              " 'teatro/matt08.txt',\n",
              " 'teatro/matt09.txt',\n",
              " 'teatro/matt10.txt',\n",
              " 'traducao/matr01.txt',\n",
              " 'traducao/matr02.txt',\n",
              " 'traducao/matr03.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = machado.raw('romance/marm05.txt')\n",
        "raw_text[5600:5800]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QCQvBHZ8l-Sv",
        "outputId": "b7eb3ae0-142e-4926-d869-2b01db6a7057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'essa anônima, ainda que não parenta, padeceu mais do que as parentas.\\nÉ verdade, padeceu mais. Não digo que se carpisse, não digo que se deixasse\\nrolar pelo chão, convulsa. Nem o meu óbito era coisa a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#texto tokenizado\n",
        "tokens = machado.words('romance/marm05.txt')\n",
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApDyKul_nJUa",
        "outputId": "94f36d42-c1d4-4bea-bbc5-bd3d1562132d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77098"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lista tokenizada em texto\n",
        "bras = Text(machado.words('romance/marm05.txt'))"
      ],
      "metadata": {
        "id": "f2fbbRd1t-sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bras.concordance('olhos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UU1WTrQvGrA",
        "outputId": "8cbb9634-950e-4b4f-8e5b-69f6d9d6fbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 25 of 138 matches:\n",
            "De pé , à cabeceira da cama , com os olhos estúpidos , a boca entreaberta , a t\n",
            "orelhas . Pela minha parte fechei os olhos e deixei - me ir à ventura . Já agor\n",
            "xões de cérebro enfermo . Como ia de olhos fechados , não via o caminho ; lembr\n",
            "gelos eternos . Com efeito , abri os olhos e vi que o meu animal galopava numa \n",
            "me apareceu então , fitando - me uns olhos rutilantes como o sol . Tudo nessa f\n",
            " mim mesmo . Então , encarei - a com olhos súplices , e pedi mais alguns anos .\n",
            "o alto de uma montanha . Inclinei os olhos a uma das vertentes , e contemplei ,\n",
            "ilhão , e , não obstante , porque os olhos do delírio são outros , eu via tudo \n",
            "cifração da eternidade . E fixei os olhos , e continuei a ver as idades , que \n",
            " esperto , concordava meu pai ; e os olhos babavam - se - lhe de orgulho , e el\n",
            "te , e , repetido o mote , cravar os olhos na testa de uma senhora , depois tos\n",
            "avrear de estômagos satisfeitos ; os olhos moles e úmidos , ou vivos e cálidos \n",
            "m estacado de orquestra , e todos os olhos se voltavam para o glosador . Quem f\n",
            " . Eu via isso , porque arrastava os olhos da compota para ele e dele para a co\n",
            " eu segui - os . O Vilaça levava nos olhos umas chispas de vinho e de volúpia .\n",
            "es ... D . Eusébia levou o lenço aos olhos . O glosador vasculhava na memória a\n",
            " estupefação imobilizou a todos ; os olhos espraiavam - se a uma e outra banda \n",
            "a aula , dava um pulo , circulava os olhos chamejantes , dizia - nos os últimos\n",
            ", deixava - se estar quieto , com os olhos espetados no ar . Uma flor , o Quinc\n",
            "u forcejava por trazer a bigode . Os olhos , vivos e resolutos , eram a minha f\n",
            " pensativa , ou levantou para mim os olhos cobiçosos . De todas porém a que me \n",
            "pouco ou nada comi , porque só tinha olhos para a dona da casa . Que gentil que\n",
            "erramava - se - lhe a felicidade dos olhos , e eu sentia - me feliz com vê - la\n",
            " meu amor ! Eu agradeci - lho com os olhos úmidos . No dia seguinte levei - lhe\n",
            "proposta . Marcela ouviu - me com os olhos no ar , sem responder logo ; como in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encontrar palavras em um contexto\n",
        "bras.findall(\"<olhos> (<.*>)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjVx0mkVzdj3",
        "outputId": "1c0e3dbb-0338-48e1-cb83-aae39e283a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estúpidos; e; fechados; e; rutilantes; súplices; a; do; ,; babavam;\n",
            "na; moles; se; da; umas; .; espraiavam; chamejantes; espetados; ,;\n",
            "cobiçosos; para; ,; úmidos; no; ;; de; de; fitos; a; naquele; do; ,;\n",
            "pretos; as; estúpidos; ao; às; ...; ,; fúlgidos; de; ,; .; de; pretos;\n",
            "tão; de; para; a; chisparam; para; me; da; ,; ,; uma; no; na; para;\n",
            "se; em; .; em; .; de; ,; no; nela; tinham; ;; cintilantes; o; dos; e;\n",
            ",; de; de; dela; vermelhos; .; e; .; o; ,; constantemente; para; ,; ,;\n",
            "para; ,; ao; ,; na; na; baixos; no; mais; no; se; dela; do; no; ,;\n",
            "lampejantes; rasos; todos; ,; e; do; pelos; de; ao; .; lhe; de;\n",
            "enfermos; :; ,; .; e; da; fixos; .; fitos; ,; ,; bonitos; de; ...; .;\n",
            "de; algum; a; ;; fitos; em\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stopwords\n",
        "\n",
        "Stopwords são palavras que podem ser consideradas irrelevantes para o entedimento do sentido de um texto, ou seja, palavras semanticamente irrelavantes."
      ],
      "metadata": {
        "id": "NOCYOBEcznKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "print(len(stopwords))\n",
        "print(stopwords[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjv5FjUzzjLw",
        "outputId": "a5d4850d-f691-46f5-b73d-69c30eb42454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "207\n",
            "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemmers\n",
        "O NLTK também possui o stemmer RSLP em Português. O código a seguir demonstra seu funcionamento:"
      ],
      "metadata": {
        "id": "1vtbMoJj5FsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "print(stemmer.stem(\"copiar\"))\n",
        "print(stemmer.stem(\"paisagem\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg422-PW5H81",
        "outputId": "c4b76fd7-7c73-4dc1-f399-2b3e6fff58a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copi\n",
            "pais\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenização\n",
        "Vimos anteriormente como tokenizar um texto utilizando expressões regulares. O NLTK também possui módulos para tokenização. Podemos tokenizar uma sequência de caracteres utilizando o método .word_tokenize(string):"
      ],
      "metadata": {
        "id": "2nabpqiK54tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Estou bem, mas não tenho certeza ... se viajarei amanhã às 8:30.\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmHBSdYw52xY",
        "outputId": "56bc591a-f238-4766-edfd-49ee14fc41af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Estou', 'bem', ',', 'mas', 'não', 'tenho', 'certeza', '...', 'se', 'viajarei', 'amanhã', 'às', '8:30', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problemas Práticos\n",
        "##POS-tagging"
      ],
      "metadata": {
        "id": "-jWVaGzLAxCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construindo um tagger"
      ],
      "metadata": {
        "id": "ZVb6BYLARlIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Carrega as sentenças rotuladas do Corpus\n",
        "sentencas_etiquetadas = mac_morpho.tagged_sents()\n",
        "tags = [tag for (word, tag) in mac_morpho.tagged_words()]"
      ],
      "metadata": {
        "id": "XViFx9U3A0Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encontrando a classe gramatical mais frequente\n",
        "nltk.FreqDist(tags).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lXMdKEHMTdr9",
        "outputId": "8c8583af-d536-4b55-d32b-65f6d8da5ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora podemos criar um tagger que etiqueta qualquer coisa com N, considerando que a classe de substantivo é a mais frequente."
      ],
      "metadata": {
        "id": "rtruYLSiUA1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "etiqPadrao = nltk.tag.DefaultTagger('N')\n",
        "etiqPadrao.tag(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eNZUxQOUADP",
        "outputId": "5f4a678b-422c-4ebc-a797-9d968d905ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Estou', 'N'),\n",
              " ('bem', 'N'),\n",
              " (',', 'N'),\n",
              " ('mas', 'N'),\n",
              " ('não', 'N'),\n",
              " ('tenho', 'N'),\n",
              " ('certeza', 'N'),\n",
              " ('...', 'N'),\n",
              " ('se', 'N'),\n",
              " ('viajarei', 'N'),\n",
              " ('amanhã', 'N'),\n",
              " ('às', 'N'),\n",
              " ('8:30', 'N'),\n",
              " ('.', 'N')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-Gram Tagging\n",
        "<br>\n",
        "<br>\n",
        "Um n-gram tagger é uma generalização de um unigram tagger cujo contexto é a\n",
        "palavra corrente em conjunto com os n-1 tokens precedentes, portanto o n-gram tagger seleciona a tag que é mais provável no contexto dado."
      ],
      "metadata": {
        "id": "aERn6MF0U4dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sents = nltk.corpus.mac_morpho.tagged_sents()\n",
        "texto = 'A manhã está ensolarada'\n",
        "tokens = nltk.word_tokenize(texto)\n",
        "unigram_tagger = nltk.tag.UnigramTagger(tagged_sents)\n",
        "unigram_tagger.tag(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GLDZNxhU0FO",
        "outputId": "81a94058-f537-43db-a4bc-5b0c7d449d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A', 'ART'), ('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sents = nltk.corpus.mac_morpho.tagged_sents()\n",
        "t0 = nltk.DefaultTagger('N')\n",
        "t1 = nltk.UnigramTagger(tagged_sents, backoff=t0)\n",
        "t2 = nltk.BigramTagger(tagged_sents, backoff=t1)\n",
        "t3 = nltk.TrigramTagger(tagged_sents, backoff=t2)\n"
      ],
      "metadata": {
        "id": "tBKpC61LZXCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa451cdc-44a6-4218-d52f-79f01f9ae4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A', 'ART'), ('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t0.tag(tokens))\n",
        "print(t1.tag(tokens))\n",
        "print(t2.tag(tokens))\n",
        "print(t3.tag(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efAt06staDEd",
        "outputId": "7e0171d1-9a82-42a4-ec78-a2fd785e4b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('A', 'N'), ('manhã', 'N'), ('está', 'N'), ('ensolarada', 'N')]\n",
            "[('A', 'ART'), ('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]\n",
            "[('A', 'ART'), ('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]\n",
            "[('A', 'ART'), ('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Salvando um tagger"
      ],
      "metadata": {
        "id": "pb-Kz9mQcJtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = open('mac_morpho.pkl', 'wb')\n",
        "dump(t3, output, -1)\n",
        "output.close()"
      ],
      "metadata": {
        "id": "5FF1SkWqcK10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando um tagger treinado"
      ],
      "metadata": {
        "id": "dnhoiUnWeb7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = open('mac_morpho.pkl', 'rb')\n",
        "tagger = load(input)\n",
        "input.close()"
      ],
      "metadata": {
        "id": "TAWWxxbvebat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extração de Informação</h2>\n",
        "O método para compreender o significado de textos é chamado extração de informação,\n",
        "no qual dados não estruturados são convertidos em dados estruturados.\n",
        "<br>\n",
        "As três primeiras tarefas podem ser executadas facilmente com o conhecimento ja adquerido até aqui usando as instruções:\n"
      ],
      "metadata": {
        "id": "d2fTNC1VfZow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#segmentação em sentenças\n",
        "text = 'De pé, à cabeceira da cama, com os olhos estúpidos, a boca entreaberta'\n",
        "sentences = nltk.sent_tokenize(text) \n",
        "# segmentação das sentenças em tokens\n",
        "sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "# etiquetagem dos tokens\n",
        "sentences = [tagger.tag(sent) for sent in sentences]\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gD0koyVfa0W",
        "outputId": "a5c35a40-24ba-4f69-bdf0-3248d94da828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('De', 'PREP|+'),\n",
              "  ('pé', 'N'),\n",
              "  (',', ','),\n",
              "  ('à', 'KS'),\n",
              "  ('cabeceira', 'N'),\n",
              "  ('da', 'N'),\n",
              "  ('cama', 'N'),\n",
              "  (',', ','),\n",
              "  ('com', 'PREP'),\n",
              "  ('os', 'ART'),\n",
              "  ('olhos', 'N'),\n",
              "  ('estúpidos', 'ADJ'),\n",
              "  (',', ','),\n",
              "  ('a', 'ART'),\n",
              "  ('boca', 'N'),\n",
              "  ('entreaberta', 'ADJ')]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sumarização de um texto"
      ],
      "metadata": {
        "id": "s8ygFeart91W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import Request, urlopen\n",
        "\n",
        "link = Request('http://ultimosegundo.ig.com.br/politica/2017-04-25/reforma-da-previdencia.html',\n",
        "               headers={'User-Agent': ''})\n",
        "pagina = urlopen(link).read().decode('utf-8', 'ignore')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(pagina, \"lxml\")\n",
        "texto = soup.find(id=\"noticia\").text\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentencas = sent_tokenize(texto)\n",
        "palavras = word_tokenize(texto.lower())\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "stopwords = set(stopwords.words('portuguese') + list(punctuation))\n",
        "palavras_sem_stopwords = [palavra for palavra in palavras if palavra not in stopwords]\n",
        "\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "frequencia = FreqDist(palavras_sem_stopwords)\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "sentencas_importantes = defaultdict(int)\n",
        "\n",
        "for i, sentenca in enumerate(sentencas):\n",
        "    for palavra in word_tokenize(sentenca.lower()):\n",
        "        if palavra in frequencia:\n",
        "            sentencas_importantes[i] += frequencia[palavra]\n",
        "\n",
        "from heapq import nlargest\n",
        "\n",
        "idx_sentencas_importantes = nlargest(4, sentencas_importantes, sentencas_importantes.get)\n",
        "\n",
        "for i in sorted(idx_sentencas_importantes):\n",
        "    print(sentencas[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htveaQ9QuC4U",
        "outputId": "2d8ca297-1ae0-426d-a2e9-8301dbbd6526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  \n",
            "\n",
            "\n",
            " Lúcio Bernardo Junior/Câmara dos Deputados - 19.4.17\n",
            "Deputados discutem na Comissão da Reforma da Previdência; com gravata roxa, o presidente do colegiado, Carlos Marun\n",
            "\n",
            "\n",
            "\n",
            "A comissão especial que analisa a proposta de reforma da Previdência na Câmara dos Deputados inicia na tarde desta terça-feira (25) a discussão do relatório apresentado na semana passada pelo relator\n",
            ", deputado Arthur Maia (PPS-BA).\n",
            "Depois de fechar acordo com parlamentares da oposição, que tentavam obstruir a sessão de leitura do parecer do relator, o presidente da comissão da reforma da Previdência\n",
            ", deputado Carlos Marun (PMDB-MS), designou que todas as reuniões desta semana sejam para discutir o relatório e apresentar pedido de vista.\n",
            "O relatório de Arthur Maia fixa a idade mínima de aposentadoria em 62 anos para as mulheres e em 65 anos para os homens após um período de transição de 20 anos.\n",
            "Para se tornar lei, a proposta de reforma da Previdência precisa, após ser aprovada na comissão especial, também passar por votação em dois turnos no plenário da Câmara e depois receber o aval do Senado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Referências\n",
        "\n",
        "Introdução ao Processamento de Linguagem Natural usando Python\n",
        "BARBOSA, J. L. N; et al. Disponível em: <https://www.facom.ufu.br/~wendelmelo/terceiros/tutorial_nltk.pdf>. Acesso em 22 de set. de 2022.\n",
        "\n",
        "Utilizando processamento de linguagem natural para criar um sumarização automática de textos\n",
        "LIMA, V. R. Disponível em: <https://medium.com/@empowerpython/utilizando-processamento-de-linguagem-natural-para-criar-um-sumariza%C3%A7%C3%A3o-autom%C3%A1tica-de-textos-775cb428c84e>. Acesso em 26 de set. de 2022."
      ],
      "metadata": {
        "id": "QHttxb54h8yz"
      }
    }
  ]
}